# FinOps 101: How to Stop Your Cloud Workload from Breaking the Bank

ROB: Thanks Arjen, thanks Guy.  Great look at the news as always.  Alright, so, tonight we have our, erm, our regular contributor Dawn.  Ah, we are very thankful for all the presentations Dawn has done so far this year, we're looking forward to another good one tonight.  Ah, Dawn, if you're able to share your screen?

DAWN: Uh, one moment please, as I try to work out how the technology actually works here.  Erm, and realize that I've- that I'm not on my title slide!  Never the greatest start.  All right, are we working?  Can you see a presentation?

ROB: Yes, I can.  All right.

DAWN: Most excellent!

ROB: [inaudible] over to you.

DAWN: Awesome, ah, hello, everyone!

ROB: Sorry, I'll just switch this over.

DAWN: Hello, everyone!  I am glad to once again be back here at the Melbourne AWS User Group from the comfort of your own homes.  So - so far this year I've looked at security, I've looked at governance, and now I'm going to look at one of the other big themes that both centralised teams and the C-Suite tend to care about, and that is cost management.  So tonight we are looking at FinOps 101, or, affectionately known as, 'How to Stop Your Cloud Workloads Breaking the Bank'.

So - I'm fairly sure that most of the people here are probably sick of my introduction by now, but for those of you who don't know who I am - my name is Dawn, I am an associate DevOps/SRE person at MYOB, and - if I want to prove my own cost saving credentials, I can dress for the opera for less than five dollars if I have to.  The most expensive part of that outfit was the stockings, which cost me two dollars fifty.  Outside of work, I am an occasional author and kitchen alchemist - sometimes that ends well, sometimes it doesn't.  I am also a raging sportsball fan, which is why that picture of me is me at Marvel Stadium.

Now - in the tech world we have an awful lot of buzzwords.  And this friendly little hand-drawn bee here would like to remind you of some of the ones that we tend to run into.  We've got things like the Internet of Things, big data, machine learning and blockchain.  We've got buzzwords that you would tend to see more from technical people; things like cloud native, test driven development, or DevOps.  So we've got all of these buzzwords, and FinOps basically just sounds like another buzzword - I mean, you've got DevOps and SecOps, so FinOps presumably just follows on from that, right?  And why should we care?

Well - FinOps isn't quite like DevOps or SecOps.  It stands for financial operations, and what it's really about is the idea of trying to get more bang for your buck in the cloud.  So it doesn't mean that we're throwing out all of our EC2 instances and changing them to `t2.micro`s because that's cheaper.  It's really about understanding - why you're using the compute power that you're using, and how you can make sure that you're using it as effectively as possible.  And that can involve a lot of different things.  It can involve working with teams to understand and manage their spend, because, often, if you have developers that don't have a huge amount of understanding of cloud computing, they might not even have looked at an AWS bill before.  All of the cloud providers, including AWS, do have their own cost management tools, which is another thing that you can leverage when you're looking at FinOps.  And finally, if that doesn't cut it, you can use third-party tools with more advanced features if you really need to save more money.  We will talk more about the cost benefit trade-off there later.

Now, when I came and talked here two months ago, ah, we met the great people at the company ProductCorp.  For those of you who didn't hear that talk, let's meet ProductCorp again.  They're a startup with a head office in Sydney, they were founded approximately five years ago, and they offer two main products.  They have a product called BuyIt, which is basically inventory management software as a service.  They also have SellIt, which is a managed online shopping platform, so something similar to Shopify.  And most importantly, for our purposes tonight, all of ProductCorp's infrastructure runs on AWS.

We have - a few different people at ProductCorp that we need to meet.  We've got Annie Jones, who is ProductCorp's current CFO, and she originally worked for an auditing firm.  Now, as you would remember from our previous talk on Control Tower, Annie is primarily focused on value for money, And she's been watching with a bit of concern as ProductCorp's cloud spent has slowly been creeping up after their organizational restructure.,  And she wants to know, is this increased cloud spend benefiting the company at the moment?  And if not, how can it?

And in order to find that out, she is going to work with Ben Nguyen.  They're ProductCorp's lead cloud engineer, and they have about 10 years of experience, mainly working for startups.  They're very passionate about improving infrastructure, and one of the things that they're hoping to be able to do with this - is to, as well as get a better understanding and visibility into the amount of money that's being spent, to make sure that teams are spending that money efficiently, and in a way that sort of advances the aims of the company and advances the quality of their software.

So what's the problem?  Well, if you saw my Control Tower talk that I gave a couple of months ago, you may remember that - basically, ProductCorp is aiming to move all of their - their products BuyIt and SellIt, from a monolith architecture to a microservices architecture, and as part of that, they've restructured their AWS accounts to move those into separate production accounts.  They've also added a dev account per microservice that's being built, and a lab account per team so that teams have somewhere to play around with things that they might want to do.  That's been really good, and it's allowed them to resolve a lot of outstanding issues that they had.  Unfortunately, since this happened, their cloud sp- their cloud spend has increased by 400 percent month on month.  And for a very small company, that is potentially unsustainable.  So Annie wants to understand why the costs have increased, and she wants to make sure that their development teams have the support that they need to manage those costs in the future.

So Annie and Ben sit down, discuss the problem, and they brainstorm some solutions.  This is what they come up with.  The first thing that they talk about is the idea that they need to go out and talk to each development team about how much their costs have increased, and they need to understand why that is.  Because if you've got suddenly got 10 or 15 times as many customers, and you're having to scale up all of your workloads for that, obviously that's a really good use of increased cloud spend.  Whereas if you've got a bunch of resources that are running in lab accounts that nobody's shut down after they've experimented, that's not such a good use of money.  Then - Ben makes Annie aware that they can use the provider dashboards to actually break down AWS costs and give teams some visibility into their usage.  So as well as the central billing portal, they can encourage their developers to have a look at the billing for each account, which allows them to break down, okay, are we spending money efficiently?  Do we understand what we're spending?  And - if we've got resources that we don't need, can we shut some of those down?

Now, Ben's been around the startup ecosystem for a while, and one of the other things that they suggest to Annie - nn, is that they can work with AWS on strategies to understand and manage cloud spend.  Now ProductCorp, as they're scaling up, is just hitting that level where they're getting to needing enterprise support, and so they're going to look into bringing someone in to talk them through those kinds of things.  And Annie, with her financial background, suggests that there might be a better way for them to visualize it.  So for more specific use-cases, she wants to investigate third-party tools and see whether there's anything there that will allow them to reduce their costs.

Now I don't know whether anyone - or everyone who's listening to this talk today has ever actually seen an AWS bill.  But for those of you who haven't - and prior to this, Annie hadn't - you're roughly looking at something that looks like this, when you enter the AWS Billing portal.  Which gives you a summary of the money that you're spending, if you're in your master billing account, gives you a summary of the money that you're spending across all of your accounts, and also gives you month to date spend by service.  So you can compare it to how much you spent the previous month, you can compare it to how much - sort of how much you've spent in past months if you go and have a look at the Cost Explorer, and you can use the bill details under the month to date spend by service to break that down a little bit more and understand what each resource is actually costing you.

When you get into Cost Explorer itself, it looks like this.  And you can see that we've got a nice breakdown that explains okay, this is what we've got going every month and this is how our costs compare to what we had for the past six months.  Now, here we're looking at EC2 instances, but you can actually change this up, and you can see a cost breakdown for every single AWS service.  I imagine that most people who work in cloud infrastructure or DevOps have probably actually seen these billing pages, but if you're a developer and you haven't, it's something that's worth looking into for the accounts that you work in, to see whether you can get that data, to actually get that better understanding then of how you would break it down.

So Annie's had a look at ProductCorp's billing data, and then Annie and Ben are going to institute their plan.  So they're going out to have some initial discussions with some of their development teams, to find out why the cloud spend has increased - and they learn a few different things.  The first thing that they learn is - as ProductCorp is moving to a microservices model, the teams are now running some of these microservices that they're currently building in production accounts alongside the old monoliths, and that's because it's not always efficient for them to remove services from the old monoliths as they're added to the microservices, as they're more focused on getting the whole migration done.

There are also a lot of new resources in the new dev accounts, so teams are going in there they're setting up development environments, they're setting up testing environments, and they're really making sure that they're getting full use of this resource.  The thing with that, though, is that ProductCorp, like many other companies, mostly works nine to five.  They don't have offices in any other country.  And so they've got these resources that are running out of hours when they don't need to be.  Because no one's going to use a development environment at two o'clock in the morning, right?  And the teams are making use of their lab accounts - to spike out new things that they want to do, and understand how best to translate their old architecture over to a microservices architecture.  The thing with that, though, is that, when they're done, they're not actually deleting their experiments, so quite a bit of this increased cloud spend is from things that people have done that are still sitting there and quietly running in lab accounts, costing them a few thousand dollars a month.

Now, the first thing that you would talk about when you want to talk about FinOps is the idea of paying upfront for things.  And Annie and Ben have previously made use of Reserved Instances, which allow you to pay upfront for EC2 instances that you know you're going to use.  So, they've already paid for the EC2 instances that BuyIt and SellIt are using, and they've taken out a reserved instance plan for some of the new instances that they anticipate that their microservices are going to use.  Now you can buy reserved instances on one year or three year terms,so previously they had renewed their old instances for a year's term, and now- that they're moving to microservices and they know that what they're doing is not going to change a lot, they're looking to translate- sort of their reserved instances for the new microservices, they want to do that on three year plans.

And there are a couple of different ways that they can do that.  So standard RIs, which is what they were using for their old micro- ah, monolith products, offer you a steeper discount - up to about 72 percent - but they're less flexible.  If AWS reduces the price of the instances that you're using, you don't benefit from that when you've taken out a standard reserved instance plan.  The other thing that they do, is they lock you into a particular instance family, so when new, more efficient, instances are released, or if you wanted to switch from different types of instances - we'll explain that in a minute - then you would have to go away and buy new reserved instance plans, and that means that you're wasting the ones that you've got.  So what Annie and Ben have done for the new ProductCorp microservice instances is they've bought convertible reserved instances, which, while they save ProductCorp less money up front, are much more flexible, because it means that if a new generation of machines comes out, and it's going to be overall cheaper for them, then they can move over to that.

One thing, however, that Annie and Ben hadn't looked at was savings plans.  And the reason why they want to take out some savings plans now is because savings plans don't just cover EC2, they cover Fargate and Lambda as well, and some of these new microservices are going to be run on Fargate.  So, the idea with savings plans is that you're not buying instances so much as you're buying compute power in advance.  So you're saying to AWS, 'Okay, I'm going to use x dollars worth of compute power every hour, and you're going to give me a discount of x percent on that'.  And you can get two different types of savings plans.  You can get savings plans that are just for EC2 compute per hour, and you can get savings plans that are for all compute per hour, which also include Lambda and Fargate.  They cover EC2 usage as well, so if you want flexibility, that's the way to go.

So, Annie and Ben take a look through the AWS pricing guide and they decide they're going to purchase some savings plans for their Fargate and their Lambda.  But it's very very complex and they're going to take my advice down here, which is that if you have an accountant, you should get them to look at it for you, to work out what the best cost benefit ratio is.  Because compute per hour tends to fluctuate quite a lot, and you have to have a pretty good understanding of the money to know how much you want to buy.

The next thing that Annie and Ben are going to do is to look for wins, and obviously they're going to start by picking off the low-hanging fruit, and trying to find the quick wins.  But once they've got through that, some of the wins that they're going to look at are not going to be quite so quick.  So - they do engage AWS enterprise support, and their new account team produces a cost report for them.  Now that cost report contains recommendations about things that they can do to save money.  Basically, it's targeted to assist them with managing their costs.  And that talks about RIs and savings plans, but it also talks about a number of other things, like shutting down inactive resources when they're not running.  It talks about spot instances and it talks about right sizing.  Annie doesn't understand that, so Ben is going to take her through the explanation as they try to improve things.

One thing that Ben identifies really quickly is that ProductCorp can use spot instances for their CI/CD agents.  Spot instances are basically spare compute capacity that's available in AWS data centres, and they're up to 90 percent cheaper than on-demand instances.  The disadvantage of this is that if the data centre needs that compute power for on-demand instances, then your spot instance can pretty much just be shut down.  So the way that this works is you set the price.  You say 'I want to buy a spot instance for x cents per hour, this type of instance', and as long as there is compute capacity available in the AWS data centres, and there aren't people who are sort of bidding higher for- higher than you for spot instances, then- you will be able to run your spot instances for as long as you want, as long as AWS doesn't need that capacity.

And the reason why Ben thinks that this is the way they should go for their CI/CD agents is that spot instances are really useful for workloads that don't need to run constantly.  Because, for a CI/CD job, that agent might only last 10 to 20 minutes before you're spinning it down, and at that point you don't necessarily want to be paying the full price of an on-demand instance.  So Ben converts all of their CI/CD agents over to spot instances, and then they start to look at the recommendations on rightsizing.  And rightsizing is basically about decreasing the size of instances that have more compute power than they need.  So if you've got an `m5.xlarge` that's running at two percent, you probably don't need an instance that big, and you can potentially scale it down.  Another thing that you can kind of look at in terms of right sizing is upgrading to newer instance families which are more efficient.  So you might upgrade from an `m4` to an `m5`, and you might find that because those newer instances are more efficient, overall it actually saves you money.

The other thing that's worth calling out, though, and it's something that's going to be very important to ProductCorp as they migrate over to microservices, is that you want to use the appropriate type of instance for your workload.  Because you've got general purpose instances, which is basically what ProductCorp was using for everything before, but now they're looking at using things like compute-optimised, memory-optimised, and storage-optimised instances.  They have some instances that are going to sit around for a long time and just have lots of information in them, then they want to use storage optimised instances for those, which will generally save them a bit of money because they're not paying for that compute power.  Whereas if they've got instances that don't really need to store anything but are doing a huge amount of computation, like say, an instance that's taking events from one place and shifting it over to another, although there are probably better ways to do that, you'd want to look at something more like a compute-optimised instance.  There are also accelerated computing instances, which are designed for - I guess you could call it processing heavy workloads, so if you were doing things like - building a machine learning model, or you were doing data analysis, or, say, video rendering, then those accelerated computing instances will allow you to do that much quicker, and much more efficiently, and potentially much cheaper than the general-purpose instances or any of the optimised instances would.

The last thing that Annie and Ben are going to look at here is hibernation and cleanup of resources that don't need to be running out of hours.  So what they want to do is, all of these development workloads that their teams are now setting up to test with, they want to shut those down at about six o'clock every day, and then restart them again at six o'clock in the morning.  And they're going to do that using CI/CD pipelines, so they automate a job that just stops all of their instances at six o'clock, and then restarts it at six o'clock the next morning.  Now the resources in the lab account should be cleaned up regularly, because you generally wouldn't want to have experiments that go too much longer than a couple of weeks.  So, as well as- getting their developers and their engineers to go in and clean up those manually on a regular basis, Ben suggests that they should leverage Service Catalog to create lifecycle policies for all of the resources in their lab accounts.  Now those can be overwritten, so that if you need something to stick around for four or six weeks while you're running a longer experiment, you can do it.  But if you don't, then you don't have to worry about remembering to clean things up because it will be shut down for you.

One other thing that's kind of useful to call out here, is that sometimes high cloud spend can be because your software is really poorly designed.  And, without saying too much, I've definitely run across more than one instance of this in the wild myself.  The thing is, though, that the cost/benefit analysis of software redesign can be really difficult, because you're going to- put in a huge amount of development, sort of development and engineering time up front to- save a lot of money down the line.

And there are a couple of things with that.  The first one is that tech debt is never good, and letting tech debt accumulate leads to things like what ProductCorp is having to do now.  But the other thing with that is that you can kind of consider, as ProductCorp is doing, going through that redesign in phases.  So they're not- sitting down and saying 'we're going to pull the whole thing out into microservices, and only then will we put it on AWS'.  They're saying 'okay, we're going to take out one microservice at a time, and make sure that those are functioning'. So that means that, potentially, if you have to stop halfway through for more urgent work, at least you're still getting some of the benefit.

And once Ben and Annie are done with that, they've managed to clean up quite a few things.  But Annie is still interested to see whether there are any other things that they can do to improve it, so they're going to go and look, then, at some third-party tools.  And there are a couple of different types of those.  So the first one is third-party cost dashboards, and that's tools such as the ones that are listed here.  Sometimes those too- tools will come in a bundle as part of complete cloud governance solutions, so you might get a piece of software that also manages, say, your ISO audits or your risk compliance, but it will come with a more advanced cost dashboard built into it.  And generally, the value for money proposition of these is that they provide you with more extensive visibility than the AWS billing portal and the Cost Explorer do.  Sometimes they themselves will provide cost-saving recommendations, sometimes they'll just surface that information in a way that's easier for you to understand.

And they have very, very different pricing models.  Some of them are flat, some of them are based on the number of accounts that you put in, ss- for some of them the pricing is based on your actual cloud spend, and some of those are going to be more or less economical, depending on the size of your company.  The other selling point for these, which is one of the reasons why Annie was interested in them, is that some of those vendors are multi-cloud.  So if you need to have workloads running across AWS, Azure, and GCP, potentially some of those vendors will allow you to see all of your cost information in one place, which gives you much more visibility.

The trick with these, though, is that, unless they're going to take their costs as a proportion of what you save by using them, you need to make sure that you're saving more money than you pay.  Erm, you can find that you sort of have some of these third-party vendors, which will say to you, 'you can save x amount of money and we're going to charge you, you know, 20 percent of x', but you can't actually save x amount of money unless you've also got four full-time engineers working on it, which is not really ideal.  So again, if you've got your accountant, that's the time to sit down and do a cost benefit analysis.

So Annie looks at the cost dashboards and decides that that's not a way that she wants to go, which finally brings her to some specialist tools.  And - these are generally things that deal with specific environments or use cases.  So they might deal with things like: cost optimization specifically for Kubernetes; spot.io leverages spot instance to reduce the cost of your EC2 workloads; some of them will actually bill themselves as going in and implementing cost savings automatically by doing the rightsizing for you.  I've never tried those out in the wild, I would be very curious to, to see whether they live up to that.

And - ProductCorp has done this, but the thing that you really want to do if you end up using any of these specialist tools, is to make sure that you cover the basics first.  So, if you haven't had a discussion about 'let's shut down our dev environment out of hours', or if you haven't had those discussions about rightsizing, the specialist tools are not necessarily going to be hugely important or useful for you.  I mean, you can't necessarily implement some of their recommendations, or use them well, unless you've really got yourself to a baseline.  And some of those specialist tools do actually require you to architect around them.

So, from that, Annie and Ben have been through their environments; they sit down at the end of it, and at the end of it they discover that, far from the 400 percent increase that they had month on month, they were now looking at their cost spen- their cloud costs being fairly steady, and only about double what they were looking at when they were running everything in one account.  And for the increased amount of customers that they're getting, that's fairly acceptable to them.

So it's time for questions.  Once again, the folks at AWS have got in contact with me, and erm, they have asked me to provide you with a QR code.  If you are interested in getting in contact with them, perhaps if you wanted to look at the recommendations that your solutions architects and technical account managers provide, or maybe if you wanted to discuss how that enterprise support can benefit you in terms of financial visibility, then feel free to use that QR code. Otherwise, thank you for having me once again, and I hope that you learned something!

ARJEN: Sorry. I was still muted.  Thanks Dawn, that was a wonderful presentation again.

DAWN: Thank you for having me!

ARJEN: I don't see a lot of questions yet, ah, we had one so far, and I'm not entirely certain how serious Jonathan Parker was about this, but the question is: 'Do savings plans cover NAT gateways?'

DAWN: [bewildered laugh] I'll, I'll let- I'll let the laughter as a response stand for that one.

ARJEN: Yeah.

DAWN: To be honest, I've never tried, but I think the answer to that is probably not.

ARJEN: I believe you are correct.  John- Another question from Jonathan: 'Are there any tools for running spot, reserved, or savings plans on Fargate or EKS for baseload and Lambda for burst?'  That's a very long question.

DAWN: It is; and look, to be honest, there's probably someone, somewhere, that's built something that will allow you to do it.  The first thing is that my comment about going for the quick wins and making sure that you've got the basics down still stands, because there's no point in architecting a solution like that, or bringing in a solution like that if you're not shutting down your dev environments at two in the morning.  And my second comment to that, I guess, would be - I'm not aware of anything, but I'm sure that if you've come up with that idea, then there's probably a market for it somewhere.  So if no one's done it yet, then maybe that's a startup idea for someone.

ARJEN: Yeah.  In addition to that, I would add, ah, when it comes to Fargate, it's- the only option there you have is the savings plan, and that gets automatically used, so that's convenient.

DAWN: Yes, my understanding of the question was that it was talking about a solution that would a- allow you to apply savings plans to Fargate and Lambda and spot instances for EC2 and basically take whatever was the cheapest for compute capacity.  But I may have misunderstood that.

ARJEN: Yeah, ah, I am not intelligent, I could also misunderstood it.  So did any other questions crop up in the meantime?  Let's do this one more.  Okay, from Priyanka:

DAWN: Mhm.

ARJEN: 'I am a data analyst and has started preparing for the Solution Architect Associate exam. My question is: do companies entertain people who are certified but have no professional experience on AWS?'

DAWN: I think - I'm not sure how related that is to what I'm talking about, I think that's probably one for the slack or for the, ah, for the catch-up afterwards.

ARJEN: Yeah.  I agree.  Okay, I think that's it then.

DAWN: Mhm. Thank you for having me again.

ARJEN: Always a pleasure.

DAWN: Yes, hopefully I can wait a few more months before I come up with my next wild idea this time.

ROB: [chuckle] Well, thank you very much Dawn.  Thank you, Arjen.  Another great, great talk. I really love the way that your talks always focus on stories. They're very entertaining, and very easy to follow. 

[Back to main talks repo](https://github.com/lisushka/talks)
